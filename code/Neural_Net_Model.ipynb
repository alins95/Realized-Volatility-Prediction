{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPff4fyh1odRzBk/FaZcZRX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alins95/kaggle-Optiver-Realized-Volatility-Prediction/blob/main/code/Neural_Net_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HN7NgGghkDK"
      },
      "outputs": [],
      "source": [
        "#Loading all the necessary libaries\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "nekiFqQqhw_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading the data**"
      ],
      "metadata": {
        "id": "eU-2foyHpGux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df_train = pd.read_csv('/content/drive/MyDrive/Data/df_train.csv')\n",
        "train = pd.read_csv('/content/drive/MyDrive/Data/train.csv')"
      ],
      "metadata": {
        "id": "irwJcJKMh1pI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing and splitting the data for training**"
      ],
      "metadata": {
        "id": "62BEzQkTitc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['target'] = train['target']\n",
        "\n",
        "df_train['stock_id'] = df_train['row_id'].apply(lambda x: int(str(x).split('-')[0]))\n",
        "\n",
        "df_train.dropna(inplace=True)\n",
        "\n",
        "row_id = df_train['row_id']\n",
        "\n",
        "target = df_train['target'].to_numpy()\n",
        "\n",
        "df_train.drop(['row_id', 'target'], axis=1, inplace=True)\n",
        "\n",
        "numeric_features = len(df_train.columns)-1\n",
        "\n",
        "stock_data = df_train['stock_id'].to_numpy()\n",
        "\n",
        "data = df_train.drop(['stock_id'], axis=1).to_numpy()\n",
        "\n",
        "X_train, X_test, stock_data_train, stock_data_test, y_train, y_test = train_test_split(data, stock_data, target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "oaJ1JO-gh6MA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scaling the data**"
      ],
      "metadata": {
        "id": "IVnfEm4pi5V9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "\n",
        "scaler.fit(X_train)\n",
        "\n",
        "X_scaled_train = scaler.transform(X_train)\n",
        "X_scaled_test = scaler.transform(X_test)\n",
        "\n",
        "X_numeric_train = torch.from_numpy(X_scaled_train).float()\n",
        "X_numeric_test = torch.from_numpy(X_scaled_test).float()\n",
        "\n",
        "X_stock_train = torch.from_numpy(stock_data_train.reshape(-1,1)).long()\n",
        "X_stock_test = torch.from_numpy(stock_data_test.reshape(-1,1)).long()\n",
        "\n",
        "y_train = torch.from_numpy(y_train).float()\n",
        "y_test = torch.from_numpy(y_test).float()"
      ],
      "metadata": {
        "id": "IHNDyPMXiiQo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the model**\n",
        "\n",
        "Our model has an embedding layer with(embedding dimension = 50) that keeps track of different stock_id's. In the forward method, we apply a sigmoid to the ouput of our network, since volatality is positive, and all the data points have volatality less than 1. We use eight hidden layers for our network, and there are no batch normalization or drop out layers. The activation function in our model is SELU."
      ],
      "metadata": {
        "id": "lFNTr23fjMhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_diff_stocks = max(df_train['stock_id'].unique())+1\n",
        "\n",
        "class Stock_Volatility(nn.Module):\n",
        "  def __init__(self, hidden_units, emd_dim, num_features):\n",
        "      super().__init__()\n",
        "      self.embd = nn.Embedding(num_of_diff_stocks, emd_dim)\n",
        "      layers = []\n",
        "      in_dim = emd_dim+num_features\n",
        "      self.out = nn.Sigmoid()\n",
        "      for l in hidden_units:\n",
        "        layers.append(nn.Linear(in_dim, l))\n",
        "        layers.append(nn.SELU())\n",
        "        in_dim = l\n",
        "      self.hidden = nn.Sequential(*layers)\n",
        "      self.output = nn.Linear(in_dim, 1)\n",
        "  def forward(self, stock_id, numeric):\n",
        "    x_stock = self.embd(stock_id.long()).squeeze(1)\n",
        "    x = torch.cat([numeric, x_stock], dim=1)\n",
        "    x = self.hidden(x)\n",
        "    return self.out(self.output(x))\n",
        "\n",
        "emd_dim = 50  #Setting the embd dimension\n",
        "\n",
        "hidden_units = [256, 256, 128, 128, 64, 64, 32, 32] #Setting the hidden layers\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "model = Stock_Volatility(hidden_units, emd_dim, numeric_features)"
      ],
      "metadata": {
        "id": "4c4fQ8xLi_4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Defining the loss function**\n",
        "\n",
        "We use rmspe loss function for the training loop defined as follows."
      ],
      "metadata": {
        "id": "zAyK4K6nkhOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmspe(y_true, y_pred):\n",
        "    ratio = (y_pred - y_true) / y_true\n",
        "    return torch.sqrt(torch.mean(ratio**2))"
      ],
      "metadata": {
        "id": "aDaOIiC6keAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparing the Batches**\n",
        "\n",
        "Our batch size is 4096."
      ],
      "metadata": {
        "id": "xZQzp3W6k3bQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = TensorDataset(X_numeric_train ,X_stock_train, y_train)\n",
        "\n",
        "loader = DataLoader(dataset, batch_size=4096, shuffle=True,\n",
        "                    num_workers=4, pin_memory=True)\n",
        "\n",
        "num_batches = len(loader)\n",
        "\n",
        "print(f'Number of batches: {num_batches}')"
      ],
      "metadata": {
        "id": "mz7tN9nek2pu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Setting up the optimizer**"
      ],
      "metadata": {
        "id": "-nqx8AfGlTFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(), lr=1e-3, weight_decay=1e-3)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)"
      ],
      "metadata": {
        "id": "OdkzsJWZkz7_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training the model**"
      ],
      "metadata": {
        "id": "jKATD5MNlgMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = rmspe\n",
        "\n",
        "\n",
        "X_stock_test = X_stock_test.to(device)\n",
        "X_numeric_test = X_numeric_test.to(device)\n",
        "y_test = y_test.to(device)\n",
        "\n",
        "epochs = 91\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "total_loss = 0\n",
        "\n",
        "for e in range(epochs):\n",
        "\n",
        "   model.train()\n",
        "\n",
        "   for batch in tqdm(loader, desc=\"Batches\", leave=True):\n",
        "\n",
        "        X_numeric_batch, X_stock_batch, y_batch = batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        X_numeric_batch = X_numeric_batch.to(device)\n",
        "        X_stock_batch = X_stock_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        y_label = model(X_stock_batch, X_numeric_batch)\n",
        "\n",
        "        loss = loss_fn(y_batch, y_label.squeeze(dim=1))\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        if e%5==0:\n",
        "          total_loss += loss.item()/num_batches\n",
        "          if torch.isnan(loss):\n",
        "              break\n",
        "\n",
        "   scheduler.step()\n",
        "\n",
        "   if e%5 == 0:\n",
        "     print(f'Epoch: {e} average training loss over all the batches: {total_loss}')\n",
        "     total_loss = 0\n",
        "     with torch.no_grad():\n",
        "            y_label_test = model(X_stock_test, X_numeric_test)\n",
        "            print(f'test loss: {loss_fn(y_test, y_label_test.squeeze(dim=1))}')"
      ],
      "metadata": {
        "id": "j9wmLswslHIH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the model**"
      ],
      "metadata": {
        "id": "bg6rHCjCn7A6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'NN_model.pth')"
      ],
      "metadata": {
        "id": "ibLn0_Ipmoki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1nHK1Rh-n14E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}