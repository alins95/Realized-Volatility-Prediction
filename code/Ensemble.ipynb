{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2c0ImJinfUYY"
   },
   "source": [
    "**Ensemble Notebook**\n",
    "\n",
    "In this notebook, we are going to ensmble the NN model and LGBM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GMqsBo1IXboX"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import lightgbm as lgb\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RTDcnSbIgHmC"
   },
   "source": [
    "**Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fEAq00mTXkR7",
    "outputId": "36090bed-b1ba-4799-a700-e6bc759cb95d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "df_train = pd.read_csv('/content/drive/MyDrive/Data/df_train.csv')\n",
    "train = pd.read_csv('/content/drive/MyDrive/Data/train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2iWiLr8fihw"
   },
   "source": [
    "**Preparing the data**\n",
    "\n",
    "The lgbm model gets the stock data as a categorial variable, but the NN_model gets it as an integer and uses the embedding layer to assign a vector in embd_dim = 50 to each stock_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SVeFppv8XmjZ"
   },
   "outputs": [],
   "source": [
    "time_order = pd.read_csv('time_order.csv')\n",
    "\n",
    "df_train['stock_id'] = df_train['row_id'].apply(lambda x: int(x.split('-')[0]))\n",
    "df_train['time_id'] = df_train['row_id'].apply(lambda x: int(x.split('-')[1]))\n",
    "\n",
    "df_train['target'] = train['target']\n",
    "\n",
    "df_train = pd.merge(df_train, time_order, on = 'time_id')\n",
    "df_train.sort_values('time_id_ordered', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "9jwWcgA3XsBz"
   },
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True)\n",
    "\n",
    "t_train = max(df_train['time_id_ordered'])*0.8\n",
    "\n",
    "X_train = df_train[df_train['time_id_ordered'] <= t_train].drop(columns=['target', 'row_id', 'time_id', 'time_id_ordered', 'stock_id']).to_numpy()\n",
    "\n",
    "stock_data_train = df_train[df_train['time_id_ordered'] <= t_train]['stock_id'].to_numpy()\n",
    "\n",
    "X_val_NN = df_train[df_train['time_id_ordered'] > t_train].drop(columns=['target', 'row_id', 'time_id', 'time_id_ordered', 'stock_id']).to_numpy()\n",
    "\n",
    "stock_data_val_NN = df_train[df_train['time_id_ordered'] > t_train]['stock_id'].to_numpy()\n",
    "\n",
    "numeric_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "VoPJWvloXw_g"
   },
   "outputs": [],
   "source": [
    "df_train['stock_id'] = df_train['row_id'].apply(lambda x: int(x.split('-')[0])).astype('category')\n",
    "\n",
    "X_val_lgb = df_train[df_train['time_id_ordered'] > t_train].drop(columns=['target', 'row_id', 'time_id', 'time_id_ordered'])\n",
    "\n",
    "y_val = df_train[df_train['time_id_ordered'] > t_train]['target'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5NeF_gU9X6ig"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_scaled_val_NN = scaler.transform(X_val_NN)\n",
    "\n",
    "X_numeric_val_NN = torch.from_numpy(X_scaled_val_NN ).float().to(device)\n",
    "\n",
    "X_stock_val_NN = torch.from_numpy(stock_data_val_NN.reshape(-1,1)).long().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "6olK8uTyYD3q"
   },
   "outputs": [],
   "source": [
    "num_of_diff_stocks = max(df_train['stock_id'].unique())+1\n",
    "\n",
    "class Stock_Volatility(nn.Module):\n",
    "  def __init__(self, hidden_units, emd_dim, num_features):\n",
    "      super().__init__()\n",
    "      self.embd = nn.Embedding(num_of_diff_stocks, emd_dim)\n",
    "      layers = []\n",
    "      in_dim = emd_dim+num_features\n",
    "      self.out = nn.Sigmoid()\n",
    "      for l in hidden_units:\n",
    "        layers.append(nn.Linear(in_dim, l))\n",
    "        layers.append(nn.SELU())\n",
    "        in_dim = l\n",
    "      self.hidden = nn.Sequential(*layers)\n",
    "      self.output = nn.Linear(in_dim, 1)\n",
    "  def forward(self, stock_id, numeric):\n",
    "    x_stock = self.embd(stock_id.long()).squeeze(1)\n",
    "    x = torch.cat([numeric, x_stock], dim=1)\n",
    "    x = self.hidden(x)\n",
    "    return self.out(self.output(x))\n",
    "\n",
    "emd_dim = 50  #Setting the embd dimension\n",
    "\n",
    "hidden_units = [256, 256, 128, 128, 64, 64, 32, 32] #Setting the hidden layers\n",
    "\n",
    "model_NN = Stock_Volatility(hidden_units, emd_dim, numeric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMyj6mnFgQID"
   },
   "source": [
    "**Load the models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tTjnOBqbYIBd"
   },
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"/content/NN_model.pth\", map_location='cpu')\n",
    "model_NN.load_state_dict(state_dict)\n",
    "\n",
    "model_lgb = lgb.Booster(model_file='/content/lgbm_model.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "T5Kg5dbjY4jE"
   },
   "outputs": [],
   "source": [
    "def rmspe(y_true, y_pred):\n",
    "    ratio = (y_pred - y_true) / y_true\n",
    "    return np.sqrt(np.mean(ratio**2))\n",
    "\n",
    "y_NN_pred_val = model_NN(X_stock_val_NN, X_numeric_val_NN).detach().numpy()\n",
    "\n",
    "\n",
    "y_lgb_pred_val = model_lgb.predict(X_val_lgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5sUeAASgVOK"
   },
   "source": [
    "**Compute the rmspe error for each model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9OrF_fKpYJQB",
    "outputId": "bc98a391-c23b-4446-aff6-f99f75d7c795"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The NN model error is 0.23769501769098272\n",
      "The LGBM model error is 0.239399752882906\n"
     ]
    }
   ],
   "source": [
    "print(f'The NN model error is {rmspe(y_val.reshape(-1,1), y_NN_pred_val)}')\n",
    "\n",
    "print(f'The LGBM model error is {rmspe(y_val, y_lgb_pred_val)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NV1r5BslgjbS"
   },
   "source": [
    "**Finding the ensemble**\n",
    "\n",
    "We use a simple convex combination of our models as our ensemble. We seach for the alpha that gives us the best validation error. The final model outperforms both models by about 0.5 on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P_YMv_MLaVLN",
    "outputId": "7325c4be-d4df-4acd-b853-037ff1c9bea5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best alpha is 0.5399999999999998\n",
      "The best error is 0.23255804998479193\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0.1,1,0.01)\n",
    "\n",
    "best_alpha = 1\n",
    "\n",
    "best_err = 1\n",
    "\n",
    "for alpha in alphas:\n",
    "  y_en = alpha*y_NN_pred_val + (1-alpha)*y_lgb_pred_val.reshape(-1,1)\n",
    "  if rmspe(y_val.reshape(-1,1), y_en)<best_err:\n",
    "    best_err = rmspe(y_val.reshape(-1,1), y_en)\n",
    "    best_alpha = alpha\n",
    "\n",
    "\n",
    "print(f'The best alpha is {best_alpha}')\n",
    "print(f'The best error is {best_err}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nPlQJd4jaqKh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
